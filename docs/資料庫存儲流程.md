# 資料庫存儲流程說明

本文件說明爬蟲程式如何將資料存入 MySQL 資料庫。

## 架構概覽

```
┌─────────────────────────────────────────────────────────────┐
│                    crawler_requests.py                       │
│  ┌─────────────────────────────────────────────────────┐    │
│  │  main()                                              │    │
│  │    ├─ 建立 DatabaseManager 物件                      │    │
│  │    ├─ 連線 MySQL                                     │    │
│  │    └─ 呼叫 batch_query_all_districts()              │    │
│  └─────────────────────────────────────────────────────┘    │
│  ┌─────────────────────────────────────────────────────┐    │
│  │  batch_query_all_districts()                         │    │
│  │    ├─ 建立批次記錄 (create_batch)                    │    │
│  │    └─ [迴圈] 每個行政區查詢完成後                    │    │
│  │         ├─ insert_records() 寫入門牌資料            │    │
│  │         └─ insert_district_result() 寫入區結果      │    │
│  └─────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                   database/db_manager.py                     │
│  ┌─────────────────────────────────────────────────────┐    │
│  │  DatabaseManager 類別                                │    │
│  │    ├─ connect()          → 連線 MySQL               │    │
│  │    ├─ create_batch()     → INSERT query_batches     │    │
│  │    ├─ insert_records()   → INSERT household_records │    │
│  │    └─ insert_district_result() → INSERT district_results│ │
│  └─────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│                      MySQL Database                          │
│  ┌─────────────┐  ┌──────────────────┐  ┌────────────────┐  │
│  │query_batches│  │household_records │  │district_results│  │
│  └─────────────┘  └──────────────────┘  └────────────────┘  │
└─────────────────────────────────────────────────────────────┘
```

## 兩階段流程

### 階段 1: main() - 初始化連線

```python
# main() 中 (crawler_requests.py)
db_manager = DatabaseManager()      # 建立 DatabaseManager 物件
db_manager.connect()                # 連線到 MySQL
```

這段程式碼的作用：
- 建立 `DatabaseManager` 物件實例
- 呼叫 `connect()` 方法連線到 MySQL 資料庫
- **此時還沒有寫入任何資料**
- `db_manager` 物件會被傳遞給 `batch_query_all_districts()` 使用

### 階段 2: batch_query_all_districts() - 實際寫入

```python
# batch_query_all_districts() 中 (crawler_requests.py)
if db_manager and batch_id and result.data:
    db_manager.insert_records(batch_id, city_name, district_name, result.data)  # 寫入門牌資料
    db_manager.insert_district_result(
        batch_id, area_code, district_name,
        result.total_count, "success" if result.total_count > 0 else "no_data"
    )  # 寫入行政區查詢結果
```

這段程式碼的作用：
- 在每個行政區查詢完成後**立即存入資料庫**
- `insert_records()`: 將門牌資料寫入 `household_records` 表
- `insert_district_result()`: 將該行政區的查詢結果寫入 `district_results` 表

## 完整流程圖

```
main()
  │
  ├─ 1. db_manager = DatabaseManager()    ← 建立物件
  │
  ├─ 2. db_manager.connect()              ← 連線 MySQL
  │
  └─ 3. crawler.batch_query_all_districts(
           ...,
           db_manager=db_manager          ← 傳入 db_manager
       )
           │
           ├─ 4. batch_id = db_manager.create_batch()  ← 建立批次記錄
           │
           └─ [迴圈每個行政區]
                 │
                 ├─ 查詢資料...
                 │
                 └─ 5. if result.success:
                        db_manager.insert_records()         ← 寫入門牌資料
                        db_manager.insert_district_result() ← 寫入區結果
```

## 各步驟對應的 SQL 操作

| 步驟 | 位置 | 方法 | SQL 操作 |
|------|------|------|----------|
| 1 | `main()` | `DatabaseManager()` | 無 (只建立物件) |
| 2 | `main()` | `connect()` | 建立 MySQL 連線 |
| 3 | `main()` | - | 傳遞 db_manager |
| 4 | `batch_query_all_districts()` | `create_batch()` | `INSERT INTO query_batches` |
| 5a | `batch_query_all_districts()` | `insert_records()` | `INSERT INTO household_records` |
| 5b | `batch_query_all_districts()` | `insert_district_result()` | `INSERT INTO district_results` |

## 資料表結構

### query_batches (查詢批次記錄)

| 欄位 | 說明 |
|------|------|
| id | 批次 ID |
| city_name | 城市名稱 |
| start_date | 查詢起始日期 |
| end_date | 查詢結束日期 |
| register_kind | 編釘類別 |
| created_at | 建立時間 |
| status | 狀態 (running/completed/failed) |

### household_records (門牌資料)

| 欄位 | 說明 |
|------|------|
| id | 資料 ID |
| batch_id | 關聯的批次 ID |
| city_name | 城市名稱 |
| district_name | 行政區名稱 |
| address | 門牌地址 |
| register_date | 編釘日期 |
| register_type | 編釘類別 |

### district_results (行政區查詢結果)

| 欄位 | 說明 |
|------|------|
| id | 結果 ID |
| batch_id | 關聯的批次 ID |
| area_code | 行政區代碼 |
| district_name | 行政區名稱 |
| record_count | 資料筆數 |
| status | 狀態 (success/no_data/failed) |
| error_message | 錯誤訊息 (如有) |

## 設計原則：關注點分離

```
crawler_requests.py          db_manager.py
┌──────────────────┐        ┌──────────────────┐
│                  │        │                  │
│  專心爬資料       │  ───▶  │  專心處理 SQL     │
│                  │        │                  │
│  - 發送請求       │        │  - 建立連線       │
│  - 解析回應       │        │  - 執行 INSERT    │
│  - 處理分頁       │        │  - 交易管理       │
│                  │        │                  │
└──────────────────┘        └──────────────────┘
```

這種設計的好處：
1. **可維護性**：修改資料庫邏輯不需要動爬蟲程式
2. **可測試性**：可以單獨測試資料庫模組
3. **可擴展性**：未來可以輕易換成其他資料庫 (PostgreSQL, SQLite 等)
4. **程式碼清晰**：每個模組職責明確

## 條件判斷說明

```python
if db_manager and batch_id and result.data:
```

這個條件確保：
- `db_manager`: 資料庫連線存在且成功
- `batch_id`: 批次記錄已建立
- `result.data`: 有資料需要存入

只有三個條件都滿足時，才會執行資料庫寫入操作。這樣可以：
- 在資料庫不可用時自動跳過存儲
- 在沒有資料時不執行無意義的 INSERT
